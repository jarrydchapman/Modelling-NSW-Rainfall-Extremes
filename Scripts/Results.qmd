---
bibliography: references.bib
---

# Results {#sec-results}

```{r, include = FALSE, message = FALSE, warning = FALSE, echo = FALSE}
library(tidyverse)
library(extRemes)
library(gridExtra)
library(readr)
library(broom)
library(NHPoisson)
library(boot)
library(cowplot)
library(patchwork)
library(ggpubr)
library(pROC)
```

```{r, include = FALSE, message = FALSE, warning = FALSE, echo = FALSE}
richmond <- read_csv("richmond.csv")
kurrajong <- read_csv("kurrajong.csv")
sydney <- read_csv("sydney.csv")
newcastle <- read_csv("newcastle.csv")
clean <- read_csv("cleanareasofinterestv2.csv")
lanina <- read_csv("lanina.csv")
enso <- read_csv("enso.csv")
set.seed(30567092)
```

```{r, echo = FALSE, include = FALSE, warning = FALSE, message = FALSE}
## Nonzero Series
richmond.nonzero <- richmond %>%
  filter(mm > 0)
kurrajong.nonzero <- kurrajong %>%
  filter(mm > 0)
sydney.nonzero <- sydney %>%
  filter(mm > 0)
newcastle.nonzero <- newcastle %>%
  filter(mm > 0)
```

## Ripley's K Function to Detect the Temporal Clustering of Extremes

To test for the significance of clustering in rainfall extremes, Ripley's K function (@eq-kfunsimp) is adopted. Using the methods outlined in @sec-ripley, Ripley's K is estimated for each station for a period of 30 days following an extreme.

```{r, echo = FALSE, include = FALSE, warning = FALSE, message = FALSE}
# time <- 30
# nsim <- 100
# ripley <- function(data) {
#   m <- matrix(NA, nrow = (nrow(data)-time), ncol = time)
# for (i in 1:(nrow(data)-time)) {
#   for (j in 1:time) {
#     m[i,j] <- sum(data[i:(i+j),10])
#   }
# }
# 
# ext975dc <- which(data$over97.5dc == 1)
# index <- matrix(NA, length(ext975dc), time)
# for (k in 1:time) {
#   index[,k] <- ext975dc
# }
# 
# df <- matrix(NA, length(ext975dc), time)
# for (i in 1:time) {
#   df[,i] <- m[index[,i] ,i]
# }
# 
# 
# rip <- df %>%
#   na.omit(df)
# rip <- rip-1
# 
# for (j in 1:time) {
#   rip[,j] <- replace(rip[,j], rip[,j] < 0, 0)
# }
# 
# rip <- colMeans(rip) %>%
#   as_tibble() %>%
#   mutate(days = 1:time) %>%
#   relocate(days)
# 
# # Homogeneous Poisson Sim
# set.seed(30567092)
# pois.df <- matrix(NA, nrow(data), nsim)
# for (i in 1:nsim) {
#   pois.df[,i] <- rpois(nrow(data), mean(data$over97.5dc))
# }
# 
# whichsim <- list()
# for (j in 1:nsim) {
#   whichsim[[j]] <- which(pois.df[,j] > 0)
# }
# 
# for (k in 1:nsim) {
#   whichsim[[k]] <- lapply(whichsim[[k]], function(indices) indices[indices <= (nrow(data)-time)])
# }
# 
# sim <- list()
# sim.df <- matrix(NA, (nrow(data)-time), time)
# for (k in 1:nsim) {
#   for (i in 1:(nrow(data)-time)) {
#     for (j in 1:time) {
#       sim.df[i,j] <- sum(pois.df[i:(i+j), k])
#     }
#   }
#   sim[[k]] <- sim.df
# }
# 
# sim.run <- vector("list", length = nsim)
# for (k in 1:nsim) {
#   sim.run[[k]] <- matrix(NA, nrow = length(whichsim[[k]]), ncol = time)
#   for (i in 1:length(whichsim[[k]])) {
#     indices <- whichsim[[k]][[i]]
#     if (length(indices) > 0) {
#       for (j in 1:time) {
#         sim.run[[k]][i, j] <- sim[[k]][indices, j]
#       }
#     }
#   }
# }
# 
# for (k in 1:nsim) {
#   for (i in 1:nrow(sim.run[[k]])) {
#     for (j in 1:ncol(sim.run[[k]])) {
#       sim.run[[k]][i, j] <- sim.run[[k]][i, j] - 1
#     }
#   }
# }
# 
# rip.pois.df <- data.frame(matrix(NA, nrow = 0, ncol = time))
# for (k in 1:nsim) {
#   pois.mean <- colMeans(sim.run[[k]], na.rm = TRUE)
#   rip.pois.df <- rbind(rip.pois.df, pois.mean)
# }
# colnames(rip.pois.df) <- paste0("V", 1:time)
# 
# prob <- c(0.005, 0.025, 0.05, 0.5, 0.95, 0.975, 0.995)
# rip.ci <- apply(rip.pois.df[1:time] , 2 , quantile , probs = prob , na.rm = TRUE) %>%
#   t %>%
#   as_tibble() %>%
#   rename("pc0.5" = "0.5%",
#          "pc2.5" = "2.5%",
#          "pc5" = "5%",
#          "pc50" = "50%",
#          "pc95" = "95%",
#          "pc97.5" = "97.5%",
#          "pc99.5" = "99.5%") %>%
#   mutate(days = 1:time) %>%
#   relocate(days)
# 
# 
# # Plot
# plot <- rip %>%
#   ggplot() +
#   geom_point(aes(days, value)) +
#   geom_line(aes(days, rip.ci$pc50), colour = "red", lwd = 1) +
#   geom_ribbon(aes(days, ymin = rip.ci$pc2.5, ymax = rip.ci$pc97.5), fill = "royalblue", alpha = 0.5) +
#   geom_ribbon(aes(days, ymin = rip.ci$pc0.5, ymax = rip.ci$pc99.5), fill = "lightblue", alpha = 0.5) +
#   theme_bw() +
#   labs(x = "Days Since Last Event",
#        y = "Ripley's K")
# 
# result <- list(plot = plot)
# return(result)
# }
```

```{r, echo = FALSE, include = FALSE, warning = FALSE, message = FALSE}
# ripley.richmond <- ripley(richmond)
# ripley.kurrajong <- ripley(kurrajong)
# ripley.sydney <- ripley(sydney)
# ripley.newcastle <- ripley(newcastle)
```

![Ripley's K-Function at each station of interest, showing evidence of temporally clustered extremes in the Hawkesbury River region.](images%5CRipley.jpeg){#fig-ripley width="600" height="300"}

Rainfall extremes in the Hawkesbury River region exhibit temporally clustered behaviour within a 30-day period (@fig-ripley). Kurrajong Heights features statistically significant clustering from day 12 to day 30 at the 1% level, corroborating the summary statistics presented in @tbl-duration. The K function is consistently above the stations median simulated homogeneous Poisson process, further supporting that the extreme arrival process is not entirely independent and that a level of temporal dependence is present.

Richmond UWS Hawkesbury exhibits no statistically significant clustering at the 1% level at any day within a 30-day period, although clustering is significant at the 5% level between day 17 and day 25. As with Kurrajong, K function values at Richmond are consistently above the median simulated HP process.

The significance of temporal clustering at Sydney and Newcastle is lower than that observed at the Hawkesbury stations, although some evidence exists. Clustering is statistically significant at the 5% level at Sydney between days 9 and 10 and remains high, although not significant through day 20. Whilst not as significant as the Hawkesbury stations, the clustering findings for Sydney still have important implications given the impact of potential flooding events on a major population hub.

There is little evidence of temporal clustering within a 30-day period at Newcastle Nobbys Signal Station, with the K function reporting similar values to that of the median simulated HP process across the period, with no significant observations at either the 1% or 5% level.

The K functions across the four stations provide stronger evidence for the temporal clustering of extremes in the Hawkesbury River region than in either of Sydney or Newcastle. Given the rivers historical propensity to flood, the significance of clustering in the region is concerning, with the probability of a flood increasing when extremes temporally compound. As evidence for temporal clustering exists for each of the Hawkesbury stations, the need for statistical models to explain and estimate the probability of extremes is justified.

## Modelling Poisson Processes for Extreme Rainfall Events in the Hawkesbury River Region

Poisson point processes are utilised to model extreme rainfall events in the Hawkesbury River region and coastal NSW. The methods applied are outlined @sec-nhpp, and the initial daily modelling provides the foundation for modelling the temporal clustering of extremes in the region.

### Homogeneous Poisson Processes for the Hawkesbury River Region

```{r, echo = FALSE, include = FALSE, warning = FALSE, message = FALSE}
#HPP
hp <- function(data, var) {
  model <- glm(var ~ 1,
               family = poisson(),
               data = data)
}

hp.models <- function(data) {
  models <- list()
  models[["hp95"]] <- hp(data, data$over95dc)
  models[["hp975"]] <- hp(data, data$over97.5dc)
  return(models)
}

hp.richmond <- hp.models(richmond)
hp.kurrajong <- hp.models(kurrajong)
hp.sydney <- hp.models(sydney)
hp.newcastle <- hp.models(newcastle)
```

```{r, echo = FALSE, include = FALSE, warning = FALSE, message = FALSE}
# Remove Declustered Obs and Scale Covariates
remove.declustered <- function(data) {
  data <- data %>%
    mutate(dc.ext = ifelse(over95 == 1 & over95dc == 0, 1, 0)) %>%
    filter(dc.ext < 1) %>%
    select(-dc.ext)
}

richmond <- remove.declustered(richmond)
kurrajong <- remove.declustered(kurrajong)
sydney <- remove.declustered(sydney)
newcastle <- remove.declustered(newcastle)


scale.fun <- function(var) {
  (var - mean(var)) / sd(var)
}

scale.covariates <- function(data) {
  data <- data %>%
    mutate(cos = scale.fun(cos),
           sin = scale.fun(sin),
           mm30 = scale.fun(mm30),
           mslp = scale.fun(mslp),
           uwind250 = scale.fun(uwind250),
           uwind850 = scale.fun(uwind850),
           soi = scale.fun(soi),
           dmi = scale.fun(dmi))
}

richmond <- scale.covariates(richmond)
kurrajong <- scale.covariates(kurrajong)
sydney <- scale.covariates(sydney)
newcastle <- scale.covariates(newcastle)
```

```{r, echo = FALSE, include = FALSE, warning = FALSE, message = FALSE}
# Models
nhpp.harm <- function(data, var) {
  model <- glm(var ~ cos + sin,
               family = poisson(),
               data = data)
}

nhpp.st <- function(data, var) {
  scope <- list(lower = glm(var ~ 1, family = poisson(),
                                 data = data),
                     upper = glm(var ~ cos + sin + mm30 + mslp + uwind250 +
                                 uwind850, 
                                 family = poisson(),
                                 data = data))
  stepwise <- step(scope$upper, scope = scope, direction = "both", k = 2)
}

nhpp.lt <- function(data, var) {
 glm(var ~ cos + sin + soi, family = poisson(),
                                 data = data)
}

nhpp.best <- function(data, var) {
  scope <- list(lower = glm(var ~ 1, family = poisson(),
                            data = data),
                upper = glm(var ~ cos + sin + mm30 + mslp + uwind250 +
                              uwind850 + soi + dmi, family = poisson(),
                            data = data))
  stepwise <- step(scope$upper, scope = scope, direction = "both", k = 2)
}

models <- function(data) {
  models <- list()
  models[["hp975"]] <- hp(data, data$over97.5dc)
  models[["nhppharm975"]] <- nhpp.harm(data, data$over97.5dc)
  models[["nhppst975"]] <- nhpp.st(data, data$over97.5dc)
  models[["nhpplt975"]] <- nhpp.lt(data, data$over97.5dc)
  models[["nhppbest975"]] <- nhpp.best(data, data$over97.5dc)
  return(models)
}

models.richmond <- models(richmond)
models.kurrajong <- models(kurrajong)
models.sydney <- models(sydney)
models.newcastle <- models(newcastle)
```

```{r, echo = FALSE, include = FALSE, warning = FALSE, message = FALSE}
fit <- function(data, model, model2) {
  fitted <- data %>%
    select(date) %>%
    mutate(over975 = data$over97.5dc,
           hp975 = model[["hp975"]]$fitted.values,
           nhppharm975 = model[["nhppharm975"]]$fitted.values,
           nhppst975 = model[["nhppst975"]]$fitted.values,
           nhpplt975 = model[["nhpplt975"]]$fitted.values,
           nhppbest975 = model[["nhppbest975"]]$fitted.values)

fitted <- fitted %>%
  complete(date = seq.Date(min(date), max(date), by = "day")) %>%
  fill(hp975, nhppharm975, nhpplt975, nhppbest975, .direction = "down")

fitted <- replace(fitted, is.na(fitted), 0)
}

fit.richmond <- fit(richmond, models.richmond, hp.richmond)
fit.kurrajong <- fit(kurrajong, models.kurrajong, hp.kurrajong)
fit.sydney <- fit(sydney, models.sydney, hp.sydney)
fit.newcastle <- fit(newcastle, models.newcastle, hp.newcastle)
```

+------------+------------------+------------------+------------------+------------------+
| Variable   | Richmond         | Kurrajong        | Sydney           | Newcastle        |
+============+==================+==================+==================+==================+
| Constant   | -4.9682 (\*\*\*) | -4.9774 (\*\*\*) | -4.9463 (\*\*\*) | -4.8088 (\*\*\*) |
|            |                  |                  |                  |                  |
|            | (0.0735)         | (0.0739)         | (0.0727)         | (0.0679)         |
+------------+------------------+------------------+------------------+------------------+
| $\ell$     | -1104.11         | -1093.86         | -1123.85         | -1260.52         |
+------------+------------------+------------------+------------------+------------------+
| AIC        | 2210.2           | 2189.7           | 2249.7           | 2523.0           |
+------------+------------------+------------------+------------------+------------------+

: Estimated coefficients for Model 1 at each station of interest, where stars denote statistical significance. {#tbl-m1}

Homogeneous Poisson processes (@eq-m1) are used to create a baseline rate of extreme rainfall occurrence at each of the Hawkesbury and coastal NSW stations. The constant rate parameter is statistically significant at each station ($p<0.01$), with the baseline intensity being approximately 0.007 at each station (@tbl-m1).

The homogeneous process at each station indicates that the baseline behaviour of extreme arrivals is comparable between the Hawkesbury, Sydney and Newcastle. With each station having similar degrees of homogeneous intensity, differences in the arrivals of extremes are implicitly caused by differences in the impact of climate drivers at each location.

### A Model for Rainfall Extreme Seasonality in the Hawkesbury Region

+------------+------------------+------------------+------------------+------------------+
| Variable   | Richmond         | Kurrajong        | Sydney           | Newcastle        |
+============+==================+==================+==================+==================+
| Constant   | -5.0447 (\*\*\*) | -5.1166 (\*\*\*) | -5.0028 (\*\*\*) | -4.9045 (\*\*\*) |
|            |                  |                  |                  |                  |
|            | (0.0793)         | (0.0846)         | (0.0769)         | (0.0745)         |
+------------+------------------+------------------+------------------+------------------+
| Cos        | 0.2850 (\*\*\*)  | 0.3744 (\*\*\*)  | 0.0041           | -0.0479          |
|            |                  |                  |                  |                  |
|            | (0.0765)         | (0.0792)         | (0.0738)         | (0.0695)         |
+------------+------------------+------------------+------------------+------------------+
| Sin        | 0.2737 (\*\*\*)  | 0.3849 (\*\*\*)  | 0.3385 (\*\*\*)  | 0.4399 (\*\*\*)  |
|            |                  |                  |                  |                  |
|            | (0.0763)         | (0.0793)         | (0.0758)         | (0.0728)         |
+------------+------------------+------------------+------------------+------------------+
| $\ell$     | -1090.47         | -1070.07         | -1113.47         | -1240.72         |
+------------+------------------+------------------+------------------+------------------+
| AIC        | 2186.9           | 2146.1           | 2232.9           | 2487.4           |
+------------+------------------+------------------+------------------+------------------+

: Estimated coefficients for Model 2 at each station of interest, where stars denote statistical significance. {#tbl-m2}

To investigate patterns of seasonality, Model 2 (@eq-m2) is fit to each station separately. The harmonic terms in this model are significant at the 1% level for the two Hawkesbury stations ($p<0.01$), however only the harmonic sin term is significant for the Sydney and Newcastle stations (@tbl-m2).

Intensity peaks in Richmond and Kurrajong in February. Process intensity in February is 1.62x and 1.86x greater than the baseline HPP at Richmond and Kurrajong respectively. Intensity is the lowest in August. Process intensity in August is 1.89x and 2.45x less than the baseline intensity at Richmond and Kurrajong respectively. This result is consistent with the monthly rainfall distributions in these regions with the majority of rainfall occurring over the summer months, and substantially less rainfall occurring in the winter months (@fig-seasonal).

The fitted intensity differs between stations in the timing of the seasonal cycle. Comparing the Hawkesbury stations of Kurrajong and Richmond to the coastal stations of Sydney and Newcastle, the peak of the seasonal cycle for the Hawkesbury stations occurs mid-February, compared to the start of April for the coastal stations. At peak intensity for the Hawkesbury stations, process intensity is 1.34x higher than in Sydney for the same day.

These findings suggest that when considering extreme rainfall events at an interannual to decadal scale in New South Wales, additional flood-related planning and resources should be allocated over the summer months to the Hawkesbury River region.

### A Subseasonal Model for Extreme Rainfall in the Hawkesbury River Region

+------------+------------------+------------------+------------------+------------------+
| Variable   | Richmond         | Kurrajong        | Sydney           | Newcastle        |
+============+==================+==================+==================+==================+
| Constant   | -5.9493 (\*\*\*) | -5.8965 (\*\*\*) | -5.7416 (\*\*\*) | -5.4785 (\*\*\*) |
|            |                  |                  |                  |                  |
|            | (0.1183)         | (0.1158)         | (0.1079)         | (0.0972)         |
+------------+------------------+------------------+------------------+------------------+
| Cos        | -0.3575 (\*\*\*) | -0.3112 (\*\*\*) | -0.3814 (\*\*\*) | -0.3649 (\*\*\*) |
|            |                  |                  |                  |                  |
|            | (0.0754)         | (0.0812)         | (0.0725)         | (0.0716)         |
+------------+------------------+------------------+------------------+------------------+
| Sin        | -0.2255 (\*\*\*) |                  |                  |                  |
|            |                  |                  |                  |                  |
|            | (0.0848)         |                  |                  |                  |
+------------+------------------+------------------+------------------+------------------+
| MM30       | 0.4817 (\*\*\*)  | 0.4116 (\*\*\*)  | 0.4545 (\*\*\*)  | 0.4911 (\*\*\*)  |
|            |                  |                  |                  |                  |
|            | (0.0381)         | (0.0363)         | (0.0396)         | (0.0386)         |
+------------+------------------+------------------+------------------+------------------+
| MSLP       | -1.0956 (\*\*\*) | -0.9869 (\*\*\*) | -0.8318 (\*\*\*) | -0.6273 (\*\*\*) |
|            |                  |                  |                  |                  |
|            | (0.0769)         | (0.0762)         | (0.0688)         | (0.0699)         |
+------------+------------------+------------------+------------------+------------------+
| UWIND      | -0.3639 (\*\*\*) | -0.3204 (\*\*\*) | -0.3241 (\*\*\*) | -0.3221 (\*\*\*) |
|            |                  |                  |                  |                  |
| 250        | (0.0986)         | (0.0992)         | (0.0975)         | (0.0893)         |
+------------+------------------+------------------+------------------+------------------+
| UWIND      | -1.1399 (\*\*\*) | -1.1437 (\*\*\*) | -0.9710 (\*\*\*) | -0.8953 (\*\*\*) |
|            |                  |                  |                  |                  |
| 850        | (0.0954)         | (0.0925)         | (0.0857)         | (0.0776)         |
+------------+------------------+------------------+------------------+------------------+
| $\ell$     | -839.35          | -851.52          | -895.22          | -1057.59         |
+------------+------------------+------------------+------------------+------------------+
| AIC        | 1692.7           | 1715.0           | 1802.4           | 2127.2           |
+------------+------------------+------------------+------------------+------------------+

: Estimated coefficients for Model 3 at each station of interest, where stars denote statistical significance. {#tbl-m3}

To analyse the impact of localised atmospheric drivers on the extreme arrivals process, the subseasonal model is used (@eq-m3). All localised climate drivers are statistically significant ($p<0.01$), indicating that wind and pressure is influential on the extreme arrival process (@tbl-m3). This is consistent with expectations as low pressure systems are associated with large rainfall totals on the eastern seaboard.

Low atmospheric pressure is associated with lower temperatures and increased rainfall. The negative sign on the mean sea level pressure coefficient is consistent with the physical process, given a negative sign suggests that process intensity increases when atmospheric pressure falls.

At Richmond and Kurrajong, a one standard deviation decrease in mean sea level pressure is associated with a 66.66% and a 62.73% increase in intensity respectively. The impact of a similar decrease in mean sea level pressure at Sydney and Newcastle is 56.47% and 46.60%. These findings suggest that the Hawkesbury River region is more susceptible to changes in atmospheric pressure than coastal NSW.

Easterly winds have a relationship with greater rainfall accumulations, supported by the negative sign of both U-wind coefficients at each location. As U-winds take a negative value when winds are easterly, the estimated coefficient indicates that the likelihood of experiencing an extreme increases with an easterly wind. The difference in magnitude between 250hpa and 850hpa suggests that winds closer to sea level have a greater impact on process intensity.

Each station is similarly impacted by U-winds at 250hpa, with a one standard deviation decrease associated with an intensity increase between 27.5%-30%. For 850hpa U-winds, there is a notable difference between the impact on the Hawkesbury region and coastal NSW. At the Hawkesbury stations, a one standard deviation decrease in U-winds at 850hpa increases intensity by approximately 68%, 10% greater than the impact for coastal NSW.

Coupled with the susceptibility of the Hawkesbury to decreases in atmospheric pressure, the impact of easterly winds on the region indicate an increased hazard during East Coast Lows. This potentially has compounding implications if the East Coast is subjective to consecutive ECLs, enhancing flood risk for the Hawkesbury.

Lagged aggregated monthly rainfall totals can be used as an indicator for extreme rainfall events, with wet weather typically preceding further rainfall. The estimated NHPPs at each location support this, as the positive sign shows that an increase in aggregated rainfall results in an increase in process intensity.

A one standard deviation increase in aggregated rainfall is associated with a 61.88% and a 50.92% increase in intensity at Richmond and Kurrajong respectively. The impact of aggregated rainfall on intensity is comparable at both Sydney and Newcastle. These effects are consistent with the temporal clustering hypothesis, as the likelihood of an extreme increases when higher rainfall totals have occurred in the previous month.

```{r, echo = FALSE, include = FALSE, warning = FALSE, message = FALSE}
intensityplot <- function(data) {
  plot <- data %>%
  ggplot() +
  geom_line(aes(date, nhppst975)) +
    labs(x = "Date",
         y = "Intensity") +
  theme_bw()
  
  return(plot)
}

m3rich <- intensityplot(fit.richmond) +
  labs(title = "Richmond")
m3kurr <- intensityplot(fit.kurrajong) +
  labs(title = "Kurrajong")
m3syd <- intensityplot(fit.sydney) +
  labs(title = "Sydney")
m3new <- intensityplot(fit.newcastle) +
  labs(title = "Newcastle")
```

```{r, echo = FALSE, warning = FALSE, message = FALSE}
#| label: fig-m3intensity
#| fig-cap: "Daily fitted intensities for the subseasonal model at each station."
plot_grid(m3rich + m3syd + m3kurr + m3new)
```

The largest fitted intensities produced by the subseasonal model (@fig-m3intensity) for the Hawkesbury region occur during the most prominent flooding events in NSW since 1950. Subseasonal intensities show spikes during 1956 for the Murray River floods, 1986 for the Hawkesbury River floods and 2022 for the Eastern Australia floods.

### A Seasonal Model for Extreme Rainfall in the Hawkesbury River Region

+------------+------------------+------------------+------------------+------------------+
| Variable   | Richmond         | Kurrajong        | Sydney           | Newcastle        |
+============+==================+==================+==================+==================+
| Constant   | -5.0574 (\*\*\*) | -5.1543 (\*\*\*) | -5.0074 (\*\*\*) | -4.9082 (\*\*\*) |
|            |                  |                  |                  |                  |
|            | (0.0801)         | (0.0869)         | (0.0772)         | (0.0748)         |
+------------+------------------+------------------+------------------+------------------+
| Cos        | 0.2765 (\*\*\*)  | 0.3592 (\*\*\*)  | -0.0007          | -0.0521          |
|            |                  |                  |                  |                  |
|            | (0.0765)         | (0.0792)         | (0.0738)         | (0.0696)         |
+------------+------------------+------------------+------------------+------------------+
| Sin        | 0.2801 (\*\*\*)  | 0.3956 (\*\*\*)  | 0.3422 (\*\*\*)  | 0.4433 (\*\*\*)  |
|            |                  |                  |                  |                  |
|            | (0.0765)         | (0.0795)         | (0.0759)         | (0.0729)         |
+------------+------------------+------------------+------------------+------------------+
| SOI        | 0.1597 (\*\*)    | 0.2755 (\*\*\*)  | 0.0959           | 0.0852           |
|            |                  |                  |                  |                  |
|            | (0.0738)         | (0.0749)         | (0.0727)         | (0.0677)         |
+------------+------------------+------------------+------------------+------------------+
| $\ell$     | -1088.11         | -1063.17         | -1112.59         | -1239.92         |
+------------+------------------+------------------+------------------+------------------+
| AIC        | 2184.2           | 2134.3           | 2233.2           | 2487.8           |
+------------+------------------+------------------+------------------+------------------+

: Estimated coefficients for Model 4 at each station of interest, where stars denote statistical significance. {#tbl-m4}

Large-scale atmospheric drivers impact the occurrence of extremes on a seasonal to annual scale, and these are captured in the seasonal model (@eq-m4). The influence of ENSO is only significant for the Hawkesbury models, indicating that ENSO has a greater impact on the extreme arrivals process in the Hawkesbury region than in coastal NSW. This is supported by earlier permutation testing results (@fig-perm) which also indicated that the Hawkesbury is more susceptible to La Niña phases.

As positive SOI index values reflect La Niña conditions, the positive sign of the estimated SOI coefficients for the Hawkesbury is consistent with expectations (@tbl-m4). This finding suggests that process intensity will increase in the Hawkesbury as the SOI index increases. A one standard deviation increase in the SOI index is associated with a 17.32% increase in intensity at Richmond and a 31.72% increase in intensity at Kurrajong Heights.

The importance of ENSO to extremes in the Hawkesbury is emphasised by the coefficients being statistically significant ($p<0.05$), whilst lacking significance for Sydney and Newcastle ($p > 0.05$). Further, the magnitude of the impact from SOI is lower at Sydney and Newcastle. The limited importance of ENSO for Sydney and Newcastle is consistent with previous findings that ENSO has limited influence on coastal NSW [@pepler2014a]. These findings suggest that an increased preparedness for extreme rainfall events is required in the Hawkesbury region during La Niña phases.

+------------+------------------+------------------+------------------+------------------+
| Variable   | Richmond         | Kurrajong        | Sydney           | Newcastle        |
+============+==================+==================+==================+==================+
| Constant   | -5.9577 (\*\*\*) | -5.8965 (\*\*\*) | -5.7629 (\*\*\*) | -5.4785 (\*\*\*) |
|            |                  |                  |                  |                  |
|            | (0.1188)         | (0.1158)         | (0.1090)         | (0.0972)         |
+------------+------------------+------------------+------------------+------------------+
| Cos        | -0.3546 (\*\*\*) | -0.3112 (\*\*\*) | -0.3882 (\*\*\*) | -0.3649 (\*\*\*) |
|            |                  |                  |                  |                  |
|            | (0.0756)         | (0.0812)         | (0.0728)         | (0.0716)         |
+------------+------------------+------------------+------------------+------------------+
| Sin        | -0.2293 (\*\*\*) |                  |                  |                  |
|            |                  |                  |                  |                  |
|            | (0.0842)         |                  |                  |                  |
+------------+------------------+------------------+------------------+------------------+
| MM30       | 0.4922 (\*\*\*)  | 0.4116 (\*\*\*)  | 0.4805 (\*\*\*)  | 0.4911 (\*\*\*)  |
|            |                  |                  |                  |                  |
|            | (0.0383)         | (0.0363)         | (0.0408)         | (0.0386)         |
+------------+------------------+------------------+------------------+------------------+
| MSLP       | -1.1144 (\*\*\*) | -0.9869 (\*\*\*) | -0.8546 (\*\*\*) | -0.6273 (\*\*\*) |
|            |                  |                  |                  |                  |
|            | (0.0779)         | (0.0762)         | (0.0693)         | (0.0699)         |
+------------+------------------+------------------+------------------+------------------+
| UWIND      | -0.3631 (\*\*\*) | -0.3204 (\*\*\*) | -0.3141 (\*\*\*) | -0.3221 (\*\*\*) |
|            |                  |                  |                  |                  |
| 250        | (0.0984)         | (0.0992)         | (0.0974)         | (0.0893)         |
+------------+------------------+------------------+------------------+------------------+
| UWIND      | -1.1534 (\*\*\*) | -1.1437 (\*\*\*) | -0.9911 (\*\*\*) | -0.8953 (\*\*\*) |
|            |                  |                  |                  |                  |
| 850        | (0.0948)         | (0.0925)         | (0.0851)         | (0.0776)         |
+------------+------------------+------------------+------------------+------------------+
| SOI        | -0.1253 (\*)     |                  | -0.1789 (\*\*\*) |                  |
|            |                  |                  |                  |                  |
|            | (0.0697)         |                  | (0.0671)         |                  |
+------------+------------------+------------------+------------------+------------------+
| $\ell$     | -837.77          | -851.52          | -891.78          | -1057.59         |
+------------+------------------+------------------+------------------+------------------+
| AIC        | 1691.5           | 1715.0           | 1797.6           | 2127.2           |
+------------+------------------+------------------+------------------+------------------+

: Estimated coefficients for Model 5 at each station of interest, where stars denote statistical significance. {#tbl-m5}

Beyond the timescales of predictability, there is interest in which covariates are most important for the extremes arrival process in the Hawkesbury. To determine this, both subseasonal and seasonal variables are considered, with the model given by @eq-m5. As with the subseasonal and seasonal models, stepwise variable selection is used to determine the 'best' model at each station. Due to the inclusion of subseasonal covariates, these models have little practical usage beyond a 30-day period.

The full model at Kurrajong and Newcastle reduces to the subseasonal model at each location, providing no additional insights beyond highlighting the importance of localised climate drivers on extreme arrivals at these locations. Richmond and Sydney also retain all subseasonal variables, however SOI is also included in the model (@tbl-m5). The inclusion of SOI for Sydney in the full model is in contention with its lack of significance in the seasonal model, although the inclusion of subseasonal covariates may aid in explaining the relationship between ENSO and extremes in Sydney.

SOI takes the opposite sign to expectations when considering the full model at Richmond and Sydney. In these models, it implied that La Niña phases actually lower intensity relative to an El Niño phase. The SOI coefficient is statistically significant at Sydney ($p<0.01$). Both of these findings are not aligned with climate reality and may be due to the current approach failing to disentangle the contribution of subseasonal drivers and ENSO to the occurrence of an extreme on a given day.

Outside of the SOI sign flip, the full models at each location reduce to a model that resembles the subseasonal models, with all variables taking signs and magnitudes consistent with those produced by the subseasonal model.

### Model Validation for Non-Homogeneous Poisson Processes

```{r, echo = FALSE, include = FALSE, warning = FALSE, message = FALSE}
# nhpp <- function(data) {
# dfst <- cbind(cos = data$cos,
#               sin = data$sin,
#               mm30 = data$mm30,
#               mslp = data$mslp,
#               uwind250 = data$uwind250,
#               uwind850 = data$uwind850)
# 
# dflt <- cbind(cos = data$cos,
#               sin = data$sin,
#               soi = data$soi)
# 
# ev <- which(data$over97.5dc > 0)
# 
# nhpp.st <- fitPP.fun(covariates = dfst,
#                        posE = ev,
#                        start = list(b0 = 0, b1 = 0, b2 = 0, b3 = 0, b4 = 0, b5 = 0, b6 = 0))
# 
# nhpp.lt <- fitPP.fun(covariates = dflt,
#                        posE = ev,
#                        start = list(b0 = 0, b1 = 0, b2 = 0, b3 = 0))
# 
# trans.st <- transfH.fun(nhpp.st)
# unires.st <- unifres.fun(trans.st$posEH)
# trans.lt <- transfH.fun(nhpp.lt)
# unires.lt <- unifres.fun(trans.lt$posEH)
# 
# nhpp <- list(nhpp.st = nhpp.st,
#              trans.st = trans.st,
#              unires.st = unires.st,
#              nhpp.lt = nhpp.lt,
#              trans.lt = trans.lt,
#              unires.lt = unires.lt)
# 
# return(nhpp)
# }
# 
# nhpp.rich <- nhpp(richmond)
# nhpp.kurr <- nhpp(kurrajong)
# 
# 
# graphresU.fun(unires = nhpp.rich$unires.lt$unires,
#               posE = nhpp.rich$trans.lt$posE)

```

Model validation is performed for the subseasonal and seasonal models at each of the Hawkesbury stations. The validation process is outlined in the methodology (@sec-nhppvalmeth), where the fitted NHPP is transformed into a HPP and a uniform distribution is obtained from the exponentiated distance between events. Model validation is then performed on the uniform behaviour of the residuals. Diagnostic plots for each model at the two Hawkesbury stations are available in the appendix (@sec-nhppval), all following discussion is based upon these.

The uniform residuals for the subseasonal model at Richmond are seemingly white noise, however there is a single significant autocorrelation at lag 14 and whilst none are significant, a pattern is apparent in the Ljung-Box p-values (@fig-subrich). A Kolmogorov-Smirnov test is used to test the suitability of a uniform distribution, with the null that a uniform distribution is appropriate and cannot be rejected at the 1% level. The combination of these factors suggests that a NHPP is an appropriate to model the subseasonal extreme arrival process.

For the seasonal model at Richmond, uniform residuals remain white noise and there are no statistically significant autocorrelations, although a pattern remains in the Ljung-Box p-values (@fig-searich). The Kolmogorov-Smirnov test cannot be rejected at the 1% level, indicating that a uniform distribution is appropriate. Similar to the subseasonal model, a NHPP is a suitable model for the seasonal extremes process at Richmond UWS Hawkesbury.

The subseasonal model at Kurrajong Heights has uniform residuals that appear to be somewhat white noise. Two significant autocorrelations occur at lag 9 and lag 17, whilst the Ljung-Box test reports no significant lags, a pattern similar to that at Richmond is present (@fig-subkurr). The null hypothesis of the Kolmogorov-Smirnov test cannot be rejected at the 1% level, suggesting the uniform distrbution is appropriate. A NHPP is appropriate to model subseasonal rainfall extremes at Kurrajong Heights.

Residuals for the seasonal model contain a degree of autocorrelation with significant lags occurring at lag 9, lag 15 and lag 18. This is corroborated with statistically significant Ljung-Box tests results past lag 15. The residuals are still visually white noise, however the remaining autocorrelation suggests that further dynamics could be captured in the modelling process (@fig-seakurr). The Kolmogorov-Smirnov test cannot be rejected at the 1% level, however may be rejected at the 5% level, indicating that a uniform distribution may not be appropriate for the residuals. Overall, a NHPP is suitable to model the seasonal process at Kurrajong Heights, although improvements to capture the remaining dynamics could be made.

```{r, echo = FALSE, include = FALSE, warning = FALSE, message = FALSE}
bootr <- function(formula, data, i) {
  d <- data[i,]
  fit <- glm(formula, family = poisson(), data = d)
  return(coef(fit))
}

boot.fun.df <- function(reps, model, data) {
bootres <- boot(statistic = bootr, R = reps,
                formula = model,
                data = data)
bootcoef <- bootres$t

return(bootcoef)
}

step.df <- list(richmondst = over97.5dc ~ cos + sin + mm30 + mslp + uwind250 + uwind850,
                richmondlt = over97.5dc ~ cos + sin + soi,
                kurrajongst = over97.5dc ~ cos + mm30 + mslp + uwind250 + uwind850,
                kurrajonglt = over97.5dc ~ cos + sin + soi,
                sydneyst = over97.5dc ~ cos + mm30 + mslp + uwind250 + uwind850,
                sydneylt = over97.5dc ~ cos + sin + soi,
                newcastlest = over97.5dc ~ cos + mm30 + mslp + uwind250 + uwind850,
                newcastlelt = over97.5dc ~ cos + sin + soi)


boot.richmond.df <- list(st = boot.fun.df(100, step.df[[1]], richmond),
                         lt = boot.fun.df(100, step.df[[2]], richmond))
boot.kurrajong.df <- list(st = boot.fun.df(100, step.df[[3]], kurrajong),
                         lt = boot.fun.df(100, step.df[[4]], kurrajong))
boot.sydney.df <- list(st = boot.fun.df(100, step.df[[5]], sydney),
                         lt = boot.fun.df(100, step.df[[6]], sydney))
boot.newcastle.df <- list(st = boot.fun.df(100, step.df[[7]], newcastle),
                         lt = boot.fun.df(100, step.df[[8]], newcastle))
```

```{r, echo = FALSE, include = FALSE, warning = FALSE, message = FALSE}
bootfit <- function(data, location) {
bootfit <- data.frame(matrix(NA, nrow(location), 1))
for(j in 1:nrow(data)) {
  bootfit[j] <- exp(data[j,1] +
                    data[j,2]*location$cos +
                    data[j,3]*location$sin +
                    data[j,4]*location$mm30 +
                    data[j,5]*location$mslp +
                    data[j,6]*location$uwind250 +
                    data[j,7]*location$uwind850)
}

  bootfit <- bootfit %>%
    as_tibble() %>%
    rename("V1" = "matrix.NA..nrow.location...1.") %>%
    mutate(date = location$date) %>%
    relocate(date)

  bootfit <- bootfit %>%
    complete(date = seq.Date(min(date), max(date), by = "day"))

  bootfit <- replace(bootfit, is.na(bootfit), 0)

  return(bootfit)
}
boot.richmond.st <- bootfit(boot.richmond.df[[1]], richmond)


bootfit <- function(data, location) {
  bootfit <- data.frame(matrix(NA, nrow(location), 1))
  for(j in 1:nrow(data)) {
    bootfit[j] <- exp(data[j,1] +
                      data[j,2]*location$cos +
                      data[j,3]*location$sin +
                      data[j,4]*location$soi)
  }

  bootfit <- bootfit %>%
    as_tibble() %>%
    rename("V1" = "matrix.NA..nrow.location...1.") %>%
    mutate(date = location$date) %>%
    relocate(date)

  bootfit <- bootfit %>%
    complete(date = seq.Date(min(date), max(date), by = "day")) %>%
    fill(names(.), .direction = "down")

  return(bootfit)
}
boot.richmond.lt <- bootfit(boot.richmond.df[[2]], richmond)
boot.kurrajong.lt <- bootfit(boot.kurrajong.df[[2]], kurrajong)
boot.sydney.lt <- bootfit(boot.sydney.df[[2]], sydney)
boot.newcastle.lt <- bootfit(boot.newcastle.df[[2]], newcastle)


bootfit <- function(data, location) {
  bootfit <- data.frame(matrix(NA, nrow(location), 1))
  for(j in 1:nrow(data)) {
    bootfit[j] <- exp(data[j,1] +
                      data[j,2]*location$cos +
                      data[j,3]*location$mm30 +
                      data[j,4]*location$mslp +
                      data[j,5]*location$uwind250 +
                      data[j,6]*location$uwind850)
  }

  bootfit <- bootfit %>%
    as_tibble() %>%
    rename("V1" = "matrix.NA..nrow.location...1.") %>%
    mutate(date = location$date) %>%
    relocate(date)

  bootfit <- bootfit %>%
    complete(date = seq.Date(min(date), max(date), by = "day"))

  bootfit <- replace(bootfit, is.na(bootfit), 0)

  return(bootfit)
}
boot.kurrajong.st <- bootfit(boot.kurrajong.df[[1]], kurrajong)
boot.sydney.st <- bootfit(boot.sydney.df[[1]], sydney)
boot.newcastle.st <- bootfit(boot.newcastle.df[[1]], newcastle)
```

```{r, echo = FALSE, include = FALSE, warning = FALSE, message = FALSE}
# Windows
startdate.fun <- function(data, size) {
  data <- data %>%
    mutate(date = as.Date(date))
  intervals <- floor(nrow(data) / size)
  obs <- intervals * size
  omit <- nrow(data) - obs
  startdate <- as.numeric(data[(1+omit), 1])
  return(startdate)
}

window.function <- function(data, startdate, size) {
  interval <- data %>%
  filter(date >= startdate)
window <- nrow(interval) / size
interval.cut <- cut(interval$date, breaks = window ,
                            labels = FALSE)
interval <- cbind(interval, interval.cut)
arrivals <- interval %>%
  select(-date)
arrivals <- arrivals %>%
  aggregate(by = list(arrivals$interval.cut),
            FUN = sum)

arrivals <- arrivals %>%
  select(-interval.cut) %>%
  rename("interval" = "Group.1") %>%
  mutate(date = seq(from = startdate, by = size, length.out = nrow(arrivals)))
arrivals <- arrivals %>%
  relocate(date, interval)
}
```

```{r, echo = FALSE, include = FALSE, warning = FALSE, message = FALSE}
# 14 Day
size <- 14
startdate <- as.Date(startdate.fun(fit.richmond, size), origin = "1970-01-01")
window.fit14 <- list(richmond = window.function(fit.richmond, startdate, size),
                     kurrajong = window.function(fit.kurrajong, startdate, size),
                     sydney = window.function(fit.sydney, startdate, size),
                     newcastle = window.function(fit.newcastle, startdate, size))

# 21 Day
size <- 21
startdate <- as.Date(startdate.fun(fit.richmond, size), origin = "1970-01-01")
window.fit21 <- list(richmond = window.function(fit.richmond, startdate, size),
                     kurrajong = window.function(fit.kurrajong, startdate, size),
                     sydney = window.function(fit.sydney, startdate, size),
                     newcastle = window.function(fit.newcastle, startdate, size))

# 30 Day
size <- 30
startdate <- as.Date(startdate.fun(fit.richmond, size), origin = "1970-01-01")
window.fit30 <- list(richmond = window.function(fit.richmond, startdate, size),
                     kurrajong = window.function(fit.kurrajong, startdate, size),
                     sydney = window.function(fit.sydney, startdate, size),
                     newcastle = window.function(fit.newcastle, startdate, size))

# 60 Day
size <- 60
startdate <- as.Date(startdate.fun(fit.richmond, size), origin = "1970-01-01")
window.fit60 <- list(richmond = window.function(fit.richmond, startdate, size),
                     kurrajong = window.function(fit.kurrajong, startdate, size),
                     sydney = window.function(fit.sydney, startdate, size),
                     newcastle = window.function(fit.newcastle, startdate, size))

# 90 Day
size <- 90
startdate <- as.Date(startdate.fun(fit.richmond, size), origin = "1970-01-01")
window.fit90 <- list(richmond = window.function(fit.richmond, startdate, size),
                     kurrajong = window.function(fit.kurrajong, startdate, size),
                     sydney = window.function(fit.sydney, startdate, size),
                     newcastle = window.function(fit.newcastle, startdate, size))

# 180 Day
size <- 180
startdate <- as.Date(startdate.fun(fit.richmond, size), origin = "1970-01-01")
window.fit180 <- list(richmond = window.function(fit.richmond, startdate, size),
                     kurrajong = window.function(fit.kurrajong, startdate, size),
                     sydney = window.function(fit.sydney, startdate, size),
                     newcastle = window.function(fit.newcastle, startdate, size))

# 365 Day
size <- 365
startdate <- as.Date(startdate.fun(fit.richmond, size), origin = "1970-01-01")
window.fit365 <- list(richmond = window.function(fit.richmond, startdate, size),
                     kurrajong = window.function(fit.kurrajong, startdate, size),
                     sydney = window.function(fit.sydney, startdate, size),
                     newcastle = window.function(fit.newcastle, startdate, size))
```

```{r, echo = FALSE, include = FALSE, warning = FALSE, message = FALSE}
# Probability Function
probge2 <- function(col) {
  1 - (((exp(-{{col}})*({{col}}^0))/factorial(0)) + ((exp(-{{col}})*({{col}}^1))/factorial(1)))
}

probge3 <- function(col) {
  1 - (((exp(-{{col}})*({{col}}^0))/factorial(0)) + ((exp(-{{col}})*({{col}}^1))/factorial(1)) +
      ((exp(-{{col}})*({{col}}^2))/factorial(2)))
}

probge4 <- function(col) {
  1 - (((exp(-{{col}})*({{col}}^0))/factorial(0)) + ((exp(-{{col}})*({{col}}^1))/factorial(1)) +
      ((exp(-{{col}})*({{col}}^2))/factorial(2)) + ((exp(-{{col}})*({{col}}^3))/factorial(3)))
}
```

```{r, echo = FALSE, include = FALSE, warning = FALSE, message = FALSE}
probs <- c(0.005, 0.025, 0.05, 0.95, 0.975, 0.995)

boot.window <- function(data, startdate, size) {
  boot <- window.function(data, startdate, size) %>%
  select(-c(date, interval)) %>%
                      t %>%
                      as_tibble()

  ci <- apply(boot[1:ncol(boot)], 2, quantile, probs = probs, na.rm = TRUE) %>%
    t %>%
    as_tibble()

  ci <- ci %>%
    mutate(date = as.Date(seq(from = startdate, by = size, length.out = nrow(ci)))) %>%
    relocate(date) %>%
    rename("pc0.5" = "0.5%",
           "pc2.5" = "2.5%",
           "pc5" = "5%",
           "pc95" = "95%",
           "pc97.5" = "97.5%",
           "pc99.5" = "99.5%")

  prfit <- ci %>%
    mutate(ppc0.5ge2 = probge2(pc0.5),
           ppc2.5ge2 = probge2(pc2.5),
           ppc5ge2 = probge2(pc5),
           ppc95ge2 = probge2(pc95),
           ppc97.5ge2 = probge2(pc97.5),
           ppc99.5ge2 = probge2(pc99.5),
           ppc0.5ge3 = probge3(pc0.5),
           ppc2.5ge3 = probge3(pc2.5),
           ppc5ge3 = probge3(pc5),
           ppc95ge3 = probge3(pc95),
           ppc97.5ge3 = probge3(pc97.5),
           ppc99.5ge3 = probge3(pc99.5),
           ppc0.5ge4 = probge4(pc0.5),
           ppc2.5ge4 = probge4(pc2.5),
           ppc5ge4 = probge4(pc5),
           ppc95ge4 = probge4(pc95),
           ppc97.5ge4 = probge4(pc97.5),
           ppc99.5ge4 = probge4(pc99.5)) %>%
    select(c(date, ppc0.5ge2, ppc2.5ge2, ppc5ge2, ppc95ge2, ppc97.5ge2, ppc99.5ge2,
             ppc0.5ge3, ppc2.5ge3, ppc5ge3, ppc95ge3, ppc97.5ge3, ppc99.5ge3,
             ppc0.5ge4, ppc2.5ge4, ppc5ge4, ppc95ge4, ppc97.5ge4, ppc99.5ge4))

  output <- list(ci = ci,
                 pr = prfit)

  return(output)
}
```

```{r, echo = FALSE, include = FALSE, warning = FALSE, message = FALSE}
# Bootstrap Intervals
size <- 14
startdate <- as.Date(startdate.fun(fit.richmond, size), origin = "1970-01-01")
bootstrap.14 <- list(richmond = boot.window(boot.richmond.st, startdate, size),
                     kurrajong = boot.window(boot.kurrajong.st, startdate, size),
                     sydney = boot.window(boot.sydney.st, startdate, size),
                     newcastle = boot.window(boot.newcastle.st, startdate, size))

size <- 21
startdate <- as.Date(startdate.fun(fit.richmond, size), origin = "1970-01-01")
bootstrap.21 <- list(richmond = boot.window(boot.richmond.st, startdate, size),
                     kurrajong = boot.window(boot.kurrajong.st, startdate, size),
                     sydney = boot.window(boot.sydney.st, startdate, size),
                     newcastle = boot.window(boot.newcastle.st, startdate, size))

size <- 30
startdate <- as.Date(startdate.fun(fit.richmond, size), origin = "1970-01-01")
bootstrap.30 <- list(richmond = boot.window(boot.richmond.st, startdate, size),
                     kurrajong = boot.window(boot.kurrajong.st, startdate, size),
                     sydney = boot.window(boot.sydney.st, startdate, size),
                     newcastle = boot.window(boot.newcastle.st, startdate, size))

size <- 60
startdate <- as.Date(startdate.fun(fit.richmond, size), origin = "1970-01-01")
bootstrap.60 <- list(richmond = boot.window(boot.richmond.st, startdate, size),
                     kurrajong = boot.window(boot.kurrajong.st, startdate, size),
                     sydney = boot.window(boot.sydney.st, startdate, size),
                     newcastle = boot.window(boot.newcastle.st, startdate, size))

size <- 90
startdate <- as.Date(startdate.fun(fit.richmond, size), origin = "1970-01-01")
bootstrap.90 <- list(richmond = boot.window(boot.richmond.st, startdate, size),
                     kurrajong = boot.window(boot.kurrajong.st, startdate, size),
                     sydney = boot.window(boot.sydney.st, startdate, size),
                     newcastle = boot.window(boot.newcastle.st, startdate, size))

size <- 180
startdate <- as.Date(startdate.fun(fit.richmond, size), origin = "1970-01-01")
bootstrap.180 <- list(richmond = boot.window(boot.richmond.lt, startdate, size),
                     kurrajong = boot.window(boot.kurrajong.lt, startdate, size),
                     sydney = boot.window(boot.sydney.lt, startdate, size),
                     newcastle = boot.window(boot.newcastle.lt, startdate, size))

size <- 365
startdate <- as.Date(startdate.fun(fit.richmond, size), origin = "1970-01-01")
bootstrap.365 <- list(richmond = boot.window(boot.richmond.lt, startdate, size),
                     kurrajong = boot.window(boot.kurrajong.lt, startdate, size),
                     sydney = boot.window(boot.sydney.lt, startdate, size),
                     newcastle = boot.window(boot.newcastle.lt, startdate, size))

```

```{r, echo = FALSE, include = FALSE, warning = FALSE, message = FALSE}
prob <- function(data) {
  prob.df <- list()
  for (i in 1:4) {
    prob.df[[i]] <- data[[i]] %>%
      mutate(ge2.975 = ifelse(over975 >= 2, 1, 0),
             hp975.p2 = probge2(hp975),
             nhppharm975.p2 = probge2(nhppharm975),
             nhppst975.p2 = probge2(nhppst975),
             nhpplt975.p2 = probge2(nhpplt975),
             nhppbest975.p2 = probge2(nhppbest975),
             ge3.975 = ifelse(over975 >= 3, 1, 0),
             hp975.p3 = probge3(hp975),
             nhppharm975.p3 = probge3(nhppharm975),
             nhppst975.p3 = probge3(nhppst975),
             nhpplt975.p3 = probge3(nhpplt975),
             nhppbest975.p3 = probge3(nhppbest975),
             ge4.975 = ifelse(over975 >= 4, 1, 0),
             hp975.p4 = probge4(hp975),
             nhppharm975.p4 = probge4(nhppharm975),
             nhppst975.p4 = probge4(nhppst975),
             nhpplt975.p4 = probge4(nhpplt975),
             nhppbest975.p4 = probge4(nhppbest975)) %>%
      relocate(over975, .before = ge2.975)
  }
  name <- c("richmond", "kurrajong", "sydney", "newcastle")
  names(prob.df) <- name
  return(prob.df)
}

prob14 <- prob(window.fit14)
prob21 <- prob(window.fit21)
prob30 <- prob(window.fit30)
prob60 <- prob(window.fit60)
prob90 <- prob(window.fit90)
prob180 <- prob(window.fit180)
prob365 <- prob(window.fit365)
```

## Disjoint Intervals of Extreme Rainfall Events

Disjoint intervals are used to assess the temporal clustering of extreme rainfall events [@ngailo2016]. The expected count of extremes in an interval can be calculated by integrating over the interval, as shown in the methodology (@sec-interval). The following analysis uses the subseasonal model for intervals between 14- and 30-days, the full model for 60- and 90-days, and the seasonal model for 180- and 365-day intervals.

+------------+---------------+-----------------+------------+------------+
| Interval   | Richmond      | Kurrajong       | Sydney     | Newcastle  |
+============+===============+=================+============+============+
| 14 Days    | 0.0971        | 0.0960          | 0.0992     | 0.1139     |
|            |               |                 |            |            |
|            | (0.0961)      | (0.0984)        | (0.1009)   | (0.1104)   |
+------------+---------------+-----------------+------------+------------+
| 30 Days    | 0.2070        | 0.2047 (\*\*\*) | 0.2115     | 0.2441     |
|            |               |                 |            |            |
|            | (0.2139)      | (0.2328)        | (0.2075)   | (0.2568)   |
+------------+---------------+-----------------+------------+------------+
| 90 Days    | 0.6182 (\*\*) | 0.6115 (\*\*\*) | 0.6351     | 0.7297     |
|            |               |                 |            |            |
|            | (0.7182)      | (0.8147)        | (0.6799)   | (0.7945)   |
+------------+---------------+-----------------+------------+------------+
| 365 Days   | 2.5068        | 2.4795 (\*)     | 2.5753     | 2.9589     |
|            |               |                 |            |            |
|            | (2.6979)      | (3.0864)        | (1.8866)   | (2.9288)   |
+------------+---------------+-----------------+------------+------------+

: Mean, variance and dispersion statistic significance for the number of extremes at each station across different periods of time, where stars denote statistical significance for the dispersion statistic. {#tbl-dispersion}

Analysis of the means and variances across different intervals at each station (@tbl-dispersion), coupled with a more formal dispersion statistic, support the K function findings of temporal clustering at the Hawkesbury stations. Statistically significant dispersion occurs in the Hawkesbury between 21- and 180-days, whilst a homogeneous process cannot be rejected at either Sydney or Newcastle.

The over-dispersion present at the Hawkesbury stations is indicative of events clustering together when they do occur, leading to more volatile interval counts, whereas the the homogeneity at Sydney and Newcastle suggests a constant rate of extreme occurrence. Further, the significant dispersion statistics at the Hawkesbury stations validate the use of a NHPP to model the arrival process, as homogeneity is rejected and a constant rate of occurrence would not be suitable.

```{r, echo = FALSE, include = FALSE, warning = FALSE, message = FALSE}
coe.plot <- function(model, bootmin, bootmax, emp, fit, hp, startdate, enddate) {
  coloursenso <- c("La Nina" = "lightblue")
  colours <- c("Empirical Count" = "black",
             "Fitted Intensity" = "red",
             "Homogeneous Intensity" = "blue")
  plot <- model %>%
    ggplot() +
    geom_rect(data = lanina, aes(xmin = xmin, xmax = xmax, ymin = ymin,
                                 ymax = ymax, fill = "La Nina"), alpha = 0.5) +
    scale_fill_manual(values = coloursenso) +
    geom_ribbon(aes(date, ymin = bootmin, ymax = bootmax), alpha = 0.5) +
    geom_point(aes(date, emp, colour = "Empirical Count")) +
    geom_line(aes(date, fit, colour = "Fitted Intensity")) +
    geom_line(aes(date, hp, colour = "Homogeneous Intensity")) +
    scale_colour_manual(values = colours) +
    xlim(as.Date(c(ymd(startdate), ymd(enddate)), format ="%Y/%m/%d")) +
    ylim(0.00001, 8) +
    labs(x = "Date",
         y = "Number of Extremes",
         colour = "Intensity",
         fill = "ENSO Phase") +
    theme_bw() +
    theme(legend.position = "none")
  
  return(plot)
}


res.plot <- function(model, actual, fitted) {
plot <- model %>%
    ggplot() +
    geom_point(aes(date, actual-fitted)) +
    labs(x = "Date",
         y = "Raw Residual") +
    theme_bw()

return(plot)
}


prob.plot <- function(model, bootmin, bootmax, ge, extdate, hpprob, fitprob, startdate, enddate) {
  coloursenso <- c("La Nina" = "lightblue")
  colours <- c("Multiple Extremes" = "red",
             "Fitted Probability" = "black")
  plot <- model %>%
    ggplot() +
    geom_rect(data = lanina, aes(xmin = xmin, xmax = xmax, ymin = ymin,
                               ymax = ymax, fill = "La Nina"), alpha = 0.5) +
    scale_fill_manual(values = coloursenso) +
    geom_ribbon(aes(date, ymin = bootmin, ymax = bootmax), alpha = 0.5) +
    geom_point(aes(date, ge, colour = "Multiple Extremes")) +
    geom_vline(xintercept = extdate, colour = "red", linetype = "dashed") +
    geom_line(aes(date, fitprob, colour = "Fitted Probability")) +
    scale_colour_manual(values = colours) +
    xlim(as.Date(c(ymd(startdate), ymd(enddate)), format ="%Y/%m/%d")) +
    ylim(0.0001, 1) +
    labs(x = "Date",
         y = "Probability",
         colour = "Probability",
         fill = "ENSO Phase") +
    theme_bw() +
    theme(legend.position = "bottom")
  
  return(plot)
}

extdate <- function(data, ge) {
  df <- data %>%
    filter(ge > 0) %>%
    select(date)
  return(df)
}

```

![30-day fitted intensities at each station of interest, showing intensity spikes during historical flooding events.](images/intensity30.png){#fig-intensity30 width="620" height="500"}

Disjoint intervals of 30 days are used to analyse the clustering behaviour of rainfall extremes over a monthly period. The 30-day fitted interval intensities for each station are shown in @fig-intensity30.

Intensity spikes at each station reflect many of the worst flooding events in recent NSW history such as the 1956 Murray River floods, the 1974 NSW floods, the 1986 Hawkesbury River floods and the 2020-2022 Eastern Australia floods. The 1956 event is observed at Richmond and Sydney with intensity increasing during this period. Similarly, the 1986 Hawkesbury floods see intensity spike at both Richmond and Kurrajong, showing that the model is capturing some of the underlying dynamics causing extreme rainfall events. Lastly, intensity increases at all stations except Newcastle during the 2022 event, providing the most time-unified intensity spike between stations in the sample.

The magnitude of intensity spikes is highest at Richmond, with Sydney also exhibiting spikes of a comparable size. Whilst of smaller magnitude, intensity increases at Kurrajong occur at similar times to those in Richmond, consistent with expectation given they are the two Hawkesbury stations. Newcastle has few increases in intensity throughout the sample, with the NHPP resembling the HPP for extended periods, which follows earlier findings of approximate homogeneity at Newcastle.

Fitted intensity appears to be associated with La Niña phases at each station except Newcastle. For the Hawkesbury region, 67% and 75% of intensities greater than 2 occur during a La Niña phase at Richmond and Kurrajong respectively. Of note, 100% of intensities greater than 2 occur during La Niña periods at Sydney. These findings are important given the subseasonal model used for 30-day intervals does not feature an ENSO-related covariate. This implies that the fitted intensity is not directly a function of ENSO, however it is apparent that teleconnections are present between ENSO and subseasonal climate drivers in the Hawkesbury River region.

The period of worst performance for each model occurs between 1990 and 2010, failing to capture many of the extremes occurring during these period. Given the potential costs of under-fitting in an extremes context, each models failure to appropriately increase intensity during intervals with 3 extremes at all stations is concerning. This suggests that there is additional climate-relevant information that is not currently being captured in the estimated models.

![90-day fitted intensities at each station of interest, showing the variation in intensity over time.](images%5Cintensity90.png){#fig-intensity90 width="620" height="500"}

To consider intervals of 90-days, the full model (@eq-m5) for each station is used, with the timespan representing the clustering of extremes over a season. The 90-day fitted intensities for each station are shown in @fig-intensity90.

Similar to the intensity spikes present for the 30-day intensities, 90-day intensities increase during notable historical flooding events. The 1956 and 2022 events have distinct spikes at all stations except Newcastle, with these events representing 2 of the 3 highest intensities at each of Richmond, Kurrajong and Sydney.

The timing and magnitude of intensity spikes are comparable across the Hawkesbury stations and Sydney, with Newcastle exhibiting some timing similarity to Sydney and little to the Hawkesbury stations. The magnitude of intensity increases at Newcastle is lower than at the other stations, with the intensity fluctuating around the HPP intensity for much of the sample.

90-day intensities at each station further support the findings from the 30-day intensities that there is an underlying relationship between ENSO and the subseasonal drivers that cause extreme events at a daily level. The Hawkesbury stations and Sydney continue to have more than two-thirds of their intensities greater than 3 occur during La Niña periods. Whilst the relationship between La Niña phases and process intensity is not as strong in Newcastle, the 90-day intensities provide evidence that a weaker association may be present.

The magnitude process intensity at each station appears to have fallen over time, largely fluctuating around the constant rate of occurrence since 1990. This finding is most apparent for the two Hawkesbury stations, where intensity is below the HPP intensity for large periods of time prior to the 2020-2022 La Niña event. This may be due to the relative sparsity of 90-day intervals experiencing 3 or more extremes since 1990 when compared to the period fo 1950 to 1990.

During the recent 2020-2022 Eastern Australia floods, intensities at each station map well to the observed data. The models perform well at each station, with all capturing the temporally clustered extremes caused by the 2022 event. Given the Eastern Australia floods were the worst to occur in the region since the 1970s, it is promising for future sustained flooding events that these models performed strongly during the recent event.

![365-day fitted intensities at each station of interest, showing that ENSO has a long-term impact on intensity in the Hawkesbury region.](images/intensity365.png){#fig-intensity365 width="620" height="500"}

Annual counts of extremes and the associated process intensity is modelled with the seasonal model (@eq-m4) and 365-day disjoint intervals. The 365-day fitted intensities are shown in @fig-intensity365.

Given forecasting skill falls as the timescale increases, and only large-scale information can be used, it is unsurprising that intensity spikes are rare and intensities fluctuate within a range of values. This is a consequence of subseasonal atmospheric drivers being the predominant seed for extreme rainfall events at a daily level.

Process intensity at each station increases during La Niña phases, however this is a function of model specification as SOI is the only large-scale climate driver retained by the stepwise selection algorithm. The intensity at each station fluctuates around the constant rate of occurrence, consistent with the inability to reject homogeneity at each station over a 365-day interval (@tbl-dispersion).

As indicated by previous findings, the Hawkesbury region is more susceptible to ENSO than coastal NSW. This is reflected in the intensity function at the Hawkesbury stations, as it has more variation than at either Sydney or Newcastle. Whilst the distinct intensity spikes that were present in the 30- and 90-day models have disappeared, it can be seen that process intensity increases in the Hawkesbury during La Niña periods.

The 365-day intensities at both Sydney and Newcastle almost collapse to the homogeneous Poisson process. This is caused by the limited impact and lack of significance of SOI at each of these stations, as well as the harmonic terms becoming a constant when evaluating an entire year.

The seasonal model is of most use for the Hawkesbury region as ENSO has an impact, whereas the model provides little benefit relative to the HPP for Sydney and Newcastle. As intensity tightly fluctuates around the constant rate of occurrence at each station, model fit for years with 5 or more extremes is poor.

When considering disjoint intervals of time, the estimated NHPP models provide benefits over simply assuming a constant rate of occurrence. The modelling process is simple and be applied across stations, using variable selection to choose station-specific covariates. Despite its ease of use, it can be seen that the model has a tendency to underfit extreme extremes. Alternative modelling techniques will be needed to bridge this gap.

### Residual Analysis for Disjoint Interval Models

To assess interval model fits, the raw residuals and error metrics are evaluated at each location across disjoint intervals of different lengths.

```{r, echo = FALSE, include = FALSE, warning = FALSE, message = FALSE}
res14 <- res.plot(window.fit14$richmond, window.fit14$richmond$over975, window.fit14$richmond$nhppst975) +
  labs(title = "14 Day Intervals")
res30 <- res.plot(window.fit30$richmond, window.fit30$richmond$over975, window.fit30$richmond$nhppst975) +
  labs(title = "30 Day Intervals")
res90 <- res.plot(window.fit90$richmond, window.fit90$richmond$over975, window.fit90$richmond$nhppbest975) +
  labs(title = "90 Day Intervals")
res365 <- res.plot(window.fit365$richmond, window.fit365$richmond$over975, window.fit365$richmond$nhpplt975) + labs(title = "365 Day Intervals")
```

```{r, echo = FALSE, warning = FALSE, message = FALSE}
#| label: fig-residuals
#| fig-cap: "Raw residuals for different periodicities at Richmond UWS Hawkesbury, showing that interval residuals resemble a white noise series."
ggarrange(res14, res30, res90, res365,
          nrow = 2, ncol = 2)
```

Behaviour in model residuals can be analysed by considering the raw residuals against time, with a residual series that resembles white noise indicative of an appropriate model fit. The residuals for each location for each interval length are exhibit similar behaviour, therefore only Richmond UWS Hawkesbury is reported in @fig-residuals.

The raw residuals for the 14-, 30- and 90-day intervals are visually similar, all being centred around zero and featuring no apparent serial correlations or heteroskedasticity. Taking absolute values, the largest residuals at each of these intervals are associated with negative residuals which result from over-predicting. Residuals caused by over-predicting are not a primary concern as they indicate the clustering behaviour was captured and conservatism is appropriate in an extremes messaging context. Large positive residuals are indicative of periods of model failure as the estimated intensity is less than the observed extreme occurrence. The intervals with positive residuals greater than two require further investigation to ascertain why the model is significantly under-predicting during these periods. The behaviour of residuals for the 14-, 30- and 90-day intervals suggest that the current modelling approach is appropriate.

Residuals for the 365-day interval demonstrate different behaviours to those of the interval lengths. Given the relatively homogeneous model fit and increased variation in observed counts, the residuals from the annual model also exhibit greater dispersion. The residuals remain centred on zero, however there appears to be decreasing trend over the sample in residual value, shifting from under-predicting to over-predicting. This is likely related to the greater proportion of extreme events occurring between 1950 and 1990 relative to the period since. This pattern in the residuals may be cause for concern, and alternative models could be considered.

```{r, echo = FALSE, include = FALSE, warning = FALSE, message = FALSE}
rmse <- function(actual, fitted) {
  sqrt(mean(((actual) - (fitted))^2))
}

mae <- function(actual, fitted) {
  mean(abs((actual) - (fitted)))
}

mupe <- function(actual, fitted) {

  prop <- ifelse(actual > fitted, 1, 0) %>%
    as_tibble()

  prop.out <- sum(prop$value) / nrow(prop)

  temp <- ifelse(actual > fitted,
                 actual - fitted, 0) %>%
    as_tibble() %>%
    filter(value > 0)

  avg <- mean(temp$value)

  score <- avg*prop.out

  out <- cbind(avg, prop.out, score)

  return(out)
  }
```

Across all intervals at each station, the NHPPs offer an improvement on a HPP in terms of lowering the mean absolute error (MAE). At the Hawkesbury stations at intervals between 14- and 90-days, the NHPPs lower MAE by approximately 18%, with longer-term intervals providing an improvement of approximately 3%.

+----------+----------+-----------+----------+-----------+
| Interval | Richmond | Kurrajong | Sydney   | Newcastle |
+==========+==========+===========+==========+===========+
| 14 Days  | 0.8293   | 0.8451    | 0.8360   | 0.8346    |
|          |          |           |          |           |
|          | (8.66%)  | (8.76%)   | (8.81%)  | (10.55%)  |
+----------+----------+-----------+----------+-----------+
| 30 Days  | 0.7843   | 0.8456    | 0.7534   | 0.8089    |
|          |          |           |          |           |
|          | (16.76%) | (16.31%)  | (17.89%) | (19.91%)  |
+----------+----------+-----------+----------+-----------+
| 90 Days  | 0.7187   | 0.7904    | 0.6385   | 0.7351    |
|          |          |           |          |           |
|          | (36.15%) | (35.14%)  | (38.51%) | (41.22%)  |
+----------+----------+-----------+----------+-----------+
| 365 Days | 1.4027   | 1.5986    | 1.2229   | 1.2516    |
|          |          |           |          |           |
|          | (45.21%) | (39.73%)  | (45.21%) | (53.42%)  |
+----------+----------+-----------+----------+-----------+

: MUPE for fitted interval counts at each station across different period lengths with proportion of observations under predicted in brackets. {#tbl-mupe}

When considering extreme weather events, an under-prediction is more harmful than over-predicting as unanticipated events can be catastrophic [@mcmartin2018]. The mean under-prediction error (MUPE) is used to assess the degree of under-prediction across different intervals. The NHPPs at each station can be further improved given the MUPE at intervals at 30-days or less are approximately 0.8, indicating that when an under-prediction occurs almost an entire event is missed on average (@tbl-mupe).

The frequency of under-prediction must also be considered to gain further context into the potential impact of under-prediction at each station. A weighted MUPE is constructed by multiplying the MUPE and the proportion of observations that are under-predicting. The weighted MUPE at the Hawkesbury stations suggest similar impact from under-prediction, whilst Sydney is least impacted and Newcastle is the most affected. If a model set existed for each interval, metrics such as MUPE and the MUPE score could be used as the loss function for an extremes model that aims to minimise under-prediction.

## Non-Homogeneous Poisson Processes for Estimating the Probability of Temporally Clustered Events

To inform risk management in the Hawkesbury region, fitted interval intensities can be used to determine the probability of extreme rainfall events being temporally clustered over a given period of time (@sec-nhppprob). The historical predicted probability is evaluated at each station using classification accuracy metrics.

### Clustering Probability During the 2020-2022 Eastern Australia Floods

```{r, include = FALSE, echo = FALSE, warning = FALSE, message = FALSE}
extdate14.rich <- extdate(prob14$richmond, prob14$richmond$ge2.975)
extdate14.kurr <- extdate(prob14$kurrajong, prob14$kurrajong$ge2.975)
extdate14.syd <- extdate(prob14$sydney, prob14$sydney$ge2.975)
extdate14.new <- extdate(prob14$newcastle, prob14$newcastle$ge2.975)
extdate90.rich <- extdate(prob90$richmond, prob90$richmond$ge3.975)
extdate90.kurr <- extdate(prob90$kurrajong, prob90$kurrajong$ge3.975)
extdate90.syd <- extdate(prob90$sydney, prob90$sydney$ge3.975)
extdate90.new <- extdate(prob90$newcastle, prob90$newcastle$ge3.975)

prob14plot.rich <- prob.plot(prob14$richmond, bootstrap.14$richmond$pr$ppc0.5ge2, bootstrap.14$richmond$pr$ppc99.5ge2, 
          prob14$richmond$ge2.975, extdate14.rich$date, prob14$richmond$hp975.p2, prob14$richmond$nhppst975.p2, ymd("2020-01-01"), ymd("2023-01-30")) +
  labs(title = "Richmond")
prob14plot.kurr <- prob.plot(prob14$kurrajong, bootstrap.14$kurrajong$pr$ppc0.5ge2, bootstrap.14$kurrajong$pr$ppc99.5ge2, 
          prob14$kurrajong$ge2.975, extdate14.kurr$date, prob14$kurrajong$hp975.p2, prob14$kurrajong$nhppst975.p2, ymd("2020-01-01"), ymd("2023-01-30")) +
  labs(title = "Kurrajong")

prob14plot.syd <- prob.plot(prob14$sydney, bootstrap.14$sydney$pr$ppc0.5ge2, bootstrap.14$sydney$pr$ppc99.5ge2, 
          prob14$sydney$ge2.975, extdate14.syd$date, prob14$sydney$hp975.p2, prob14$sydney$nhppst975.p2, ymd("2020-01-01"), ymd("2023-01-30")) +
  labs(title = "Sydney")

prob14plot.new <- prob.plot(prob14$newcastle, bootstrap.14$newcastle$pr$ppc0.5ge2, bootstrap.14$newcastle$pr$ppc99.5ge2, 
          prob14$newcastle$ge2.975, extdate14.new$date, prob14$newcastle$hp975.p2, prob14$newcastle$nhppst975.p2, ymd("2020-01-01"), ymd("2023-01-30")) +
  labs(title = "Newcastle")

prob90plot.rich <- prob.plot(prob90$richmond, bootstrap.90$richmond$pr$ppc0.5ge3, bootstrap.90$richmond$pr$ppc99.5ge3, 
          prob90$richmond$ge3.975, extdate90.rich$date, prob90$richmond$hp975.p3, prob90$richmond$nhppst975.p3, ymd("1950-01-01"), ymd("2023-01-30")) +
  labs(title = "Richmond UWS Hawkesbury")
prob90plot.kurr <- prob.plot(prob90$kurrajong, bootstrap.90$kurrajong$pr$ppc0.5ge3, bootstrap.90$kurrajong$pr$ppc99.5ge3, 
          prob90$kurrajong$ge3.975, extdate90.kurr$date, prob90$kurrajong$hp975.p3, prob90$kurrajong$nhppst975.p3, ymd("1950-01-01"), ymd("2023-01-30")) +
  labs(title = "Kurrajong Heights")
prob90plot.syd <- prob.plot(prob90$sydney, bootstrap.90$sydney$pr$ppc0.5ge3, bootstrap.90$sydney$pr$ppc99.5ge3, 
          prob90$sydney$ge3.975, extdate90.syd$date, prob90$sydney$hp975.p3, prob90$sydney$nhppst975.p3, ymd("1950-01-01"), ymd("2023-01-30")) +
  labs(title = "Sydney Botanic Gardens")
prob90plot.new <- prob.plot(prob90$newcastle, bootstrap.90$newcastle$pr$ppc0.5ge3, bootstrap.90$newcastle$pr$ppc99.5ge3, 
          prob90$newcastle$ge3.975, extdate90.new$date, prob90$newcastle$hp975.p3, prob90$newcastle$nhppst975.p3, ymd("1950-01-01"), ymd("2023-01-30")) +
  labs(title = "Newcastle Nobbys Signal Station")
```

```{r, echo = FALSE, warning = FALSE, message = FALSE}
#| label: fig-prob14
#| fig-cap: "14-day temporal clustering probability during the 2020-2022 Eastern Australia floods at each station of interest."
ggarrange(prob14plot.rich, prob14plot.kurr, prob14plot.syd, prob14plot.new, nrow = 2, ncol = 2,
          common.legend = TRUE, legend = "bottom")
```

The Eastern Australia floods and associated 'triple dip' La Niña caused the worst flooding in the Hawkesbury River region since the 1970s. As shown in @fig-intensity30 and @fig-intensity90, the recent flooding events appear to be well modelled at each station, we now consider whether the models provide appropriate probability estimates for the temporal clustering of extremes.

During the 2020-2022 event, Richmond and Sydney were the only stations to endure a 14-day period with 2 extreme arrivals. The estimated probability of clustered extremes at the start of March 2022 jumps to 73% at Richmond and 87% at Sydney (@fig-prob14). Kurrajong and Newcastle also experienced their highest probability of clustering during the same fortnight, however Kurrajong experienced a single extreme and Newcastle did not experience any. A similar shared jump in probability occurs in early 2020, which, despite no temporal clustering of events at any station, marked the start of the Eastern Australia flooding event.

The model fails to capture the March 2021 event in Richmond, having an estimated clustering probability of 1.6% during this period. A small spike in probability can be seen at the three other stations during the same period, despite none of these stations experiencing clustered events. This provides a valuable example of how the methods developed in this paper can be used indicatively but cannot be solely relied upon and emphasises the need for future research to extend into a spatial setting.

Throughout this period, the HPP model has a constant clustering probability of 0.5%. This illustrates the practical use and importance of developing models which can incorporate dynamic information to evaluate the hazard of temporally clustered extreme events.

### Historical Temporal Clustering Probability over 90-Day Intervals

![Estimated probabilities of experiencing 3 or more extremes over a 90-day period at each station of interest, showing probability jumps during historical flooding events.](images/prob90.png){#fig-prob90 width="620" height="500"}

For the clustering of extremes over a 90-day interval, periods with three or more extremes are considered to exhibit temporal clustering. @fig-prob90 shows that increases in probability at each location have comparable timing. This is likely a result of the increased timespan considered, smoothing weekly locational differences.

Visual inspection suggests that the clustered extremes are generally associated with a jump in probability. The flooding events of the 1970s are appropriately modelled at each station, with this period being the most similar between stations in terms of probabilities and the actual clustering of extremes.

In addition to the 1970s events, the probability of clustering during the events in the 1950s and 2022 are also appropriately modelled. However, clustered extremes that occur outside of larger events do not have appropriate probability estimates. This indicates that the models are capable of estimating clustering probability during long-term events, but struggle with extremes that cluster independent of a long-term event.

Consistent with fitted intensities over the same period, the estimated probabilities of clustering are largely near zero between 1990 and 2010. This holds true for the Hawkesbury stations and Sydney, however Newcastle does exhibit some variation in this timeframe. Further, during the same 20-year period, Newcastle has 3 clustered events whilst Kurrajong is the only other station to experience one. A possible explanation is Newcastle's geographic positioning north of both Sydney and the Hawkesbury.

The 90-day setting provides further evidence that a time-varying process is valuable for modelling the clustering of extremes, with the constant model estimating a 90-day probability of 13%. The HPP would fail to model the repeated jumps in probabilities during long-term events and would under-predict extremes clustering as a result.

### Extreme Rainfall Event Classification Metrics

To more formally evaluate whether the estimated clustering probabilities fit the observed clustering of extremes, classification metrics and the ROC curve are considered. In an extremes setting, there is a trade-off between failing to predict events, and predicting events too often, leading to a situation where warnings are no longer heeded. To reflect this trade-off, the false negative rate (FNR) and the false positive rate (FPR) are the two metrics of interest, as FNR is the proportion of events missed and FPR is the probability of causing unnecessary concern where an event does not occur. With this trade-off in mind, a threshold, $q$, of 0.1 is used for the 14- and 90-day probabilities of observing 2 or more and 3 or more extremes respectively.

```{r, echo = FALSE, include = FALSE, warning = FALSE, message = FALSE}
metrics <- function(data, actual, prob, q) {
  tp <- ifelse(actual == 1 & prob >= q, 1, 0)
  fp <- ifelse(actual == 0 & prob >= q, 1, 0)
  tn <- ifelse(actual == 0 & prob < q, 1, 0)
  fn <- ifelse(actual == 1 & prob < q, 1, 0)
  
  naive <- (nrow(data) - (sum(tp) + sum(fn))) / nrow(data) 
  accuracy <- (sum(tp) + sum(tn)) / nrow(data)
  tpr <- sum(tp) / (sum(tp) + sum(fn))
  fpr <- sum(fp) / (sum(tn) + sum(fp))
  tnr <- sum(tn) / (sum(tn) + sum(fp))
  fnr <- sum(fn) / (sum(tp) + sum(fn))
  
  metric <- cbind(naive, accuracy, tpr, fpr, tnr, fnr)
  nam <- c("naive", "accuracy", "tpr", "fpr", "tnr", "fnr")
metric <- setNames(metric, nam)

return(metric)
}

roc.fun <- function(data, actual, prob) {
  q <- c(seq(from = 0, to = 1, by = 0.001))
  df <- data.frame(matrix(0, nrow = 1001, ncol = 6))
for (j in 1:1001) {
  df[j,] <- metrics(data, actual,
                            prob, q[j])
}
nam <- c("naive", "accuracy", "tpr", "fpr", "tnr", "fnr")
df <- setNames(df, nam) %>%
  mutate(q = q) %>%
  relocate(q, .before = "naive")

return(df)
}

rocplot <- function(data) {
colours <- c("Harmonic" = "green",
             "Subseasonal" = "blue",
             "Seasonal" = "purple",
             "Full" = "orange")
 ggplot() +
  geom_line(aes(data$harmonic$fpr, data$harmonic$tpr, colour = "Harmonic")) +
  geom_line(aes(data$st$fpr, data$st$tpr, colour = "Subseasonal")) +
  geom_line(aes(data$lt$fpr, data$lt$tpr, colour = "Seasonal")) +
  geom_line(aes(data$best$fpr, data$best$tpr, colour = "Full")) +
  scale_colour_manual(values = colours) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", colour = "red") +
  labs(x = "False Positive Rate",
       y = "True Positive Rate",
       colour = "Model") +
   theme_bw()
}
```

```{r, echo = FALSE, include = FALSE, warning = FALSE, message = FALSE}
roc14.rich <- list(harmonic = roc.fun(prob14$richmond, prob14$richmond$ge2.975,
                            prob14$richmond$nhppharm975.p2),
          st = roc.fun(prob14$richmond, prob14$richmond$ge2.975,
                            prob14$richmond$nhppst975.p2),
          lt = roc.fun(prob14$richmond, prob14$richmond$ge2.975,
                            prob14$richmond$nhpplt975.p2),
          best = roc.fun(prob14$richmond, prob14$richmond$ge2.975,
                            prob14$richmond$nhppbest975.p2))

roc30.rich <- list(harmonic = roc.fun(prob30$richmond, prob30$richmond$ge2.975,
                            prob30$richmond$nhppharm975.p2),
          st = roc.fun(prob30$richmond, prob30$richmond$ge2.975,
                            prob30$richmond$nhppst975.p2),
          lt = roc.fun(prob30$richmond, prob30$richmond$ge2.975,
                            prob14$richmond$nhpplt975.p2),
          best = roc.fun(prob30$richmond, prob30$richmond$ge2.975,
                            prob30$richmond$nhppbest975.p2))

roc90.rich <- list(harmonic = roc.fun(prob90$richmond, prob90$richmond$ge3.975,
                            prob90$richmond$nhppharm975.p3),
          st = roc.fun(prob90$richmond, prob90$richmond$ge3.975,
                            prob90$richmond$nhppst975.p3),
          lt = roc.fun(prob90$richmond, prob90$richmond$ge3.975,
                            prob90$richmond$nhpplt975.p3),
          best = roc.fun(prob90$richmond, prob90$richmond$ge3.975,
                            prob90$richmond$nhppbest975.p3))

roc365.rich <- list(harmonic = roc.fun(prob365$richmond, prob365$richmond$ge4.975,
                            prob365$richmond$nhppharm975.p4),
          st = roc.fun(prob365$richmond, prob365$richmond$ge4.975,
                            prob365$richmond$nhppst975.p4),
          lt = roc.fun(prob365$richmond, prob365$richmond$ge4.975,
                            prob365$richmond$nhpplt975.p4),
          best = roc.fun(prob365$richmond, prob365$richmond$ge4.975,
                            prob365$richmond$nhppbest975.p4))


rocplot14 <- rocplot(roc14.rich) + labs(title = "14 Day Intervals")
rocplot30 <- rocplot(roc30.rich) + labs(title = "30 Day Intervals")
rocplot90 <- rocplot(roc90.rich) + labs(title = "90 Day Intervals")
rocplot365 <- rocplot(roc365.rich) + labs(title = "365 Day Intervals")
```

```{r, echo = FALSE, warning = FALSE, message = FALSE}
#| label: fig-roc
#| fig-cap: "ROC Curves for different periodicities at Richmond UWS Hawkesbury, showing that the full model is the best for classification."
ggarrange(rocplot14, rocplot30, rocplot90, rocplot365, nrow = 2, ncol = 2,
          common.legend = TRUE, legend = "bottom")
```

ROC curves can be used to determine which model is most suitable for classification, which in this setting means deciding whether extreme events are temporally clustered within an interval. Curves that are closer to the Y-axis are considered better classifiers, as they maximise the area under curve (AUC), with the red dotted line representing a random classifier where a clustered extremes label is by chance. ROC curves for four intervals are shown in @fig-roc for Richmond, however the findings hold for each station.

For each interval, the 'best' classifier is the full model, consistent with the initial stepwise selection algorithm choosing from the entire covariate set. The performance of the full and subseasonal models deteriorate as the interval length increases, likely due to unincorporated large scale drivers and randomness having greater procedural impact over longer time periods. The inverse effect also holds, where the seasonal model performs poorly over short intervals but improves at longer timeframes, being best at 90 days.

The behaviour of the seasonal and harmonic models across intervals significantly differs from that of the subseasonal and full models. For 14- and 30-day intervals, a seasonal classifier of clustering is little better than randomly assigning a clustering label and performs worse than the model with only harmonic terms. The ROC curve for the 365-day model sees the harmonic curve follow the random classifier line, due to the model reducing to a constant when evaluated at a 365-day interval.

ROC curve analysis indicates that the full model is the best classifier for whether extremes are temporally clustered, however consideration must also be given to overall accuracy and more importantly, the false negative rate.

All reported AUCs and classification metrics are based upon the full model.

+----------------+------------+------------+------------+------------+
| Statistic      | Richmond   | Kurrajong  | Sydney     | Newcastle  |
+================+============+============+============+============+
| Naive Accuracy | 0.9958     | 0.9942     | 0.9953     | 0.9953     |
+----------------+------------+------------+------------+------------+
| Model Accuracy | 0.9779     | 0.9779     | 0.9806     | 0.9753     |
+----------------+------------+------------+------------+------------+
| FPR            | 0.0205     | 0.0185     | 0.0174     | 0.0211     |
+----------------+------------+------------+------------+------------+
| FNR            | 0.3750     | 0.6364     | 0.4444     | 0.7778     |
+----------------+------------+------------+------------+------------+
| AUC            | 0.9703     | 0.9664     | 0.9601     | 0.9237     |
+----------------+------------+------------+------------+------------+

: 14-day interval classification accuracy metrics for each station. {#tbl-class14}

When considering 14-day intervals, model accuracy and naive accuracy are comparable across stations, with the naive classification performing slightly better (@tbl-class14). As the naive model assumes that all intervals will not feature temporally clustered extremes, the focus on anticipating clustered extremes is lost, whilst also creating a difficult benchmark to outperform given the extremes themselves are rare. Model accuracy is highest at Sydney and AUC is maximised at Richmond, performance at Kurrajong is comparable and Newcastle is the worst classifier of the group.

The FPR-FNR trade-off sees FNR minimised at Richmond, with 37.5% of clustered extremes misclassified, and FPR most favourable for Sydney at 1.74%. When considering FPR in a timescale sense, 1.74% implies that a false positive can be expected at Sydney approximately once every two years. This information is useful from both a messaging and modelling perspective. In a modelling sense, lowering the classification threshold becomes more justifiable if it means the FNR is reduced, as an increase in FPR from once every two years is reasonable. In terms of messaging, classifying an event as likely to be temporally clustered is more likely to be cause for general concern, when only misclassified once every two years.

The accuracy metrics for a 14-day interval indicate that despite performing worse than a naive model in terms of accuracy, there is value to be found in estimating the probability of clustered events to lower the FNR, given the potential impact of missing events.

+----------------+------------+------------+------------+------------+
| Statistic      | Richmond   | Kurrajong  | Sydney     | Newcastle  |
+================+============+============+============+============+
| Naive Accuracy | 0.9595     | 0.9561     | 0.9696     | 0.9595     |
+----------------+------------+------------+------------+------------+
| Model Accuracy | 0.9054     | 0.9088     | 0.9088     | 0.8682     |
+----------------+------------+------------+------------+------------+
| FPR            | 0.0916     | 0.0848     | 0.0906     | 0.1268     |
+----------------+------------+------------+------------+------------+
| FNR            | 0.1667     | 0.2308     | 0.1111     | 0.2500     |
+----------------+------------+------------+------------+------------+
| AUC            | 0.9575     | 0.9475     | 0.9601     | 0.8803     |
+----------------+------------+------------+------------+------------+

: 90-day interval classification accuracy metrics for each station. {#tbl-class90}

Model and naive accuracy over 90-day intervals are similar across stations, except Newcastle where accuracy is approximately 4% lower than the other stations (@tbl-class90). As with the 14-day intervals, model accuracy is maximised at Sydney, with AUC also being maximised at Sydney for 90-day intervals. Newcastle remains the worst fitting classifier, although model performance at Kurrajong has worsened.

Richmond and Sydney exhibit similar FPR and FNR behaviour, with the FNR considerably lower at each station relative to the 14-day interval classifier. When considering 90-day intervals, only 10-15% of clustered extremes are now misclassified, reducing the impacts of under-prediction. The trade-off has seen FPR increase at each station, by approximately 9% at the Hawkesbury stations and Sydney. Applying a similar timescale transformation as performed for the 14-day interval, the FPR implies a false alarm approximately once every three years for 90-day intervals.

The messaging remains similar to that for 14-day intervals, with the additional benefit of a lower FNR improving overall confidence in the models informative power. As the FPR-FNR trade-off has improved, the need to increase the FPR to lower FNR is less essential for 90-day intervals than at 14-day intervals.

As suggested for predicted probabilities for 14-day intervals, despite lower accuracy than the benchmark, the improvements to the FNR justify the use of the estimated NHPP to determine the probability of clustered extremes.

The justification for using a time-varying NHPP to estimate the probability of temporal clustering is consistent across all interval sizes, as any possible action to lower the false negative rate and therefore provide the community warning of extreme rainfall clustering is beneficial.
